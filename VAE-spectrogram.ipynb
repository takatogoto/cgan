{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, itertools, pickle, random, glob, imageio\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_load_album(datapath, labelpath, imgsize):\n",
    "    \"\"\"\n",
    "    datapath 'jpeg' file of album image\n",
    "    labelpath 'png' file of spectrogram \n",
    "    \"\"\"\n",
    "    datalist = os.listdir(datapath)\n",
    "    datasize = len(datalist)\n",
    "    #print(datasize)\n",
    "    \n",
    "    data_ = np.zeros((datasize, imgsize, imgsize, 3))\n",
    "    label_ = np.zeros((datasize, imgsize, imgsize, 3))\n",
    "    outputlist = []\n",
    "    nonelist = []\n",
    "    for i, fname in enumerate(datalist):\n",
    "        if glob.glob(os.path.join(labelpath, fname[:-4] + '*')):\n",
    "        #f os.path.isfile(os.path.join(labelpath, fname[:-4] + 'png')):\n",
    "            #print('there is file')\n",
    "            img_d = Image.open(os.path.join(datapath, fname)\n",
    "                              ).resize((imgsize, imgsize))\n",
    "            img_l = Image.open(os.path.join(labelpath, fname[:-4]+'png')\n",
    "                              ).convert('RGB').resize((imgsize, imgsize))\n",
    "            data_[i] = np.asarray(img_d)\n",
    "            label_[i] = np.asarray(img_l)\n",
    "            img_d.close()\n",
    "            img_l.close()\n",
    "            #print(fname[:-4])\n",
    "            outputlist.append(fname[:-5])\n",
    "            \n",
    "        else:\n",
    "            nonelist.append(i)\n",
    "            #print(i, 'is empty')\n",
    "            \n",
    "    data = np.delete(data_, nonelist, 0)\n",
    "    label = np.delete(label_, nonelist, 0)\n",
    "    return data, label, outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load albumdata\n",
    "\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('WGAN-GP-TensorFlow', 'datasets', 'album')\n",
    "audiopath = os.path.join('audio','spec256')\n",
    "\n",
    "samples, labels, datalist= dataset_load_album(\n",
    "    datapath, audiopath, img_size)\n",
    "\n",
    "samples = samples/255\n",
    "labels = labels/255\n",
    "\n",
    "input_dim = img_size * img_size * 3\n",
    "num_sample = samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load('x_samples.npy')\n",
    "input_dim = img_size * img_size * 3\n",
    "num_sample = samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_samples.npy', samples)\n",
    "np.save('x_labels.npy', labels)\n",
    "np.save('x_datalist.npy', datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, input_dim =input_dim, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.build()\n",
    "\n",
    "        self.sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "        allow_soft_placement=True,log_device_placement=True))\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        \n",
    "        self.x = tf.placeholder(\n",
    "            name='x', dtype=tf.float32, shape=[None, self.input_dim])\n",
    "\n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, 2048, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "        f2 = fc(f1, 1024, scope='enc_fc2', activation_fn=tf.nn.relu)\n",
    "        f3 = fc(f2, 512, scope='enc_fc3', activation_fn=tf.nn.relu)\n",
    "        f4 = fc(f3, 256, scope='enc_fc4', activation_fn=tf.nn.relu)\n",
    "        f5 = fc(f4, 128, scope='enc_fc5', activation_fn=tf.nn.relu)\n",
    "        f6 = fc(f5, 64, scope='enc_fc6', activation_fn=tf.nn.relu)\n",
    "        self.z_mu = fc(f6, self.n_z, scope='enc_fc7_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f6, self.n_z, scope='enc_fc7_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(\n",
    "            shape=tf.shape(self.z_log_sigma_sq),\n",
    "            mean=0, stddev=1, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 64, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(g1, 128, scope='dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, 256, scope='dec_fc3', activation_fn=tf.nn.relu)\n",
    "        g4 = fc(g3, 1024, scope='dec_fc4', activation_fn=tf.nn.relu)\n",
    "        g5 = fc(g4, 1024, scope='dec_fc5', activation_fn=tf.nn.relu)\n",
    "        g6 = fc(g5, 2048, scope='dec_fc6', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g6, self.input_dim, scope='dec_fc7', \n",
    "                        activation_fn=tf.sigmoid)\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "        epsilon = 1e-10\n",
    "        recon_loss = -tf.reduce_sum(\n",
    "            self.x * tf.log(epsilon+self.x_hat) + \n",
    "            (1-self.x) * tf.log(epsilon+1-self.x_hat), \n",
    "            axis=1\n",
    "        )\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss)\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }        \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x):\n",
    "        _, losses = self.sess.run(\n",
    "            [self.train_op, self.losses],\n",
    "            feed_dict={self.x: x}\n",
    "        )\n",
    "        return losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x, sess):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_album(model_object, sample, input_dim =input_dim, learning_rate=1e-4, \n",
    "            batch_size=16, num_epoch=5, n_z=16, log_step=5,\n",
    "                 num_sample = num_sample):\n",
    "    model = model_object(\n",
    "        learning_rate=learning_rate, batch_size=batch_size, n_z=n_z,\n",
    "    input_dim =input_dim)\n",
    "    \n",
    "    \n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            step += 1\n",
    "            # Get a batch\n",
    "            batch = sample[iter * batch_size : (iter + 1) * batch_size]\n",
    "            # Execute the forward and backward pass \n",
    "            # Report computed losses\n",
    "            #print('batch',batch)\n",
    "            losses = model.run_single_step(batch)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if epoch % log_step == 0:\n",
    "            log_str = '[Epoch {}] '.format(epoch)\n",
    "            for k, v in losses.items():\n",
    "                log_str += '{}: {:.3f}  '.format(k, v)\n",
    "            log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "            print(log_str)\n",
    "            \n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] recon_loss: 7031.131  latent_loss: 9.392  total_loss: 7040.523  (18.953 sec/epoch)\n",
      "[Epoch 5] recon_loss: 6872.486  latent_loss: 11.086  total_loss: 6883.571  (18.769 sec/epoch)\n",
      "[Epoch 10] recon_loss: 6782.181  latent_loss: 11.040  total_loss: 6793.221  (18.767 sec/epoch)\n",
      "[Epoch 15] recon_loss: 6797.075  latent_loss: 12.537  total_loss: 6809.612  (18.768 sec/epoch)\n",
      "[Epoch 20] recon_loss: 6737.233  latent_loss: 11.878  total_loss: 6749.111  (18.808 sec/epoch)\n",
      "[Epoch 25] recon_loss: 6718.814  latent_loss: 12.268  total_loss: 6731.082  (18.822 sec/epoch)\n",
      "[Epoch 30] recon_loss: 6745.427  latent_loss: 11.137  total_loss: 6756.564  (18.858 sec/epoch)\n",
      "[Epoch 35] recon_loss: 6728.536  latent_loss: 11.604  total_loss: 6740.141  (18.846 sec/epoch)\n",
      "[Epoch 40] recon_loss: 6745.925  latent_loss: 11.993  total_loss: 6757.917  (18.832 sec/epoch)\n",
      "[Epoch 45] recon_loss: 6708.328  latent_loss: 11.189  total_loss: 6719.516  (18.823 sec/epoch)\n",
      "[Epoch 50] recon_loss: 6716.850  latent_loss: 11.584  total_loss: 6728.434  (18.749 sec/epoch)\n",
      "[Epoch 55] recon_loss: 6748.383  latent_loss: 12.881  total_loss: 6761.263  (18.750 sec/epoch)\n",
      "[Epoch 60] recon_loss: nan  latent_loss: nan  total_loss: nan  (18.831 sec/epoch)\n",
      "[Epoch 65] recon_loss: nan  latent_loss: nan  total_loss: nan  (18.809 sec/epoch)\n",
      "[Epoch 70] recon_loss: nan  latent_loss: nan  total_loss: nan  (18.822 sec/epoch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-53ba1e90f61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model_2d_vae = trainer_album(VariantionalAutoencoder, samples.reshape(-1,input_dim), \n\u001b[1;32m      6\u001b[0m                              \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                              input_dim =input_dim, num_sample=num_sample)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ba73df19e9e2>\u001b[0m in \u001b[0;36mtrainer_album\u001b[0;34m(model_object, sample, input_dim, learning_rate, batch_size, num_epoch, n_z, log_step, num_sample)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Report computed losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#print('batch',batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-15d650f82573>\u001b[0m in \u001b[0;36mrun_single_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m         _, losses = self.sess.run(\n\u001b[1;32m     86\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "#with tf.device('/cpu:0'):\n",
    "with tf.device('/gpu:0'):\n",
    "    model_2d_vae = trainer_album(VariantionalAutoencoder, samples.reshape(-1,input_dim), \n",
    "                             num_epoch=200, batch_size=64, n_z=2, \n",
    "                             input_dim =input_dim, num_sample=num_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model: generation\n",
    "# Sample noise vectors from N(0, 1)\n",
    "z = np.random.normal(size=[model_2d_vae.batch_size, model_2d_vae.n_z])\n",
    "x_generated = model_2d_vae.generator(z)\n",
    "\n",
    "n = np.sqrt(model_2d_vae.batch_size).astype(np.int32)\n",
    "I_generated = np.empty((img_size*n, img_size*n, 3))\n",
    "#print(x_generated.shape)\n",
    "for i in range(n):\n",
    "    #print(i)\n",
    "    I_generated[i*img_size:(i+1)*img_size, i*img_size:(i+1)*img_size, :\n",
    "               ] = x_generated[i].reshape(img_size, img_size, 3)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(I_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and save latent z\n",
    "z_transform = model_2d_vae.transformer(samples.reshape(-1,img_size*img_size*3))\n",
    "np.save('z_tras.npy', z_transform)\n",
    "np.save('z_list.npy', datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_val_load = np.load('z_tras.npy')\n",
    "z_list_load = list(np.load('z_list.npy'))\n",
    "print(type(z_list_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z_list_load))\n",
    "print(z_val_load.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
